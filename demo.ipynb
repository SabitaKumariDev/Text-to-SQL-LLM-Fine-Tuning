{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyMen8SA45USlDyZKtrkUGQ/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install pyngrok streamlit unsloth ragas"],"metadata":{"id":"7Hh5eIlyIRUa","executionInfo":{"status":"ok","timestamp":1745547286605,"user_tz":240,"elapsed":8,"user":{"displayName":"gscolabpro","userId":"15075203482406901392"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["# Step 1: In your Colab notebook, run this first\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_X0p9IydJQMn","executionInfo":{"status":"ok","timestamp":1745545205927,"user_tz":240,"elapsed":15858,"user":{"displayName":"gscolabpro","userId":"15075203482406901392"}},"outputId":"5dcec92c-b509-4e6c-ab1e-a97f50dc3ed7"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%%writefile sql_generator_app.py\n","import streamlit as st\n","import torch\n","from unsloth import FastLanguageModel\n","from peft import PeftModel\n","import time\n","import pandas as pd\n","import re\n","import os\n","import asyncio\n","from ragas.metrics import LLMSQLEquivalence\n","from ragas.dataset_schema import SingleTurnSample\n","import openai\n","from ragas.llms import llm_factory\n","import sqlglot\n","\n","# Set OpenAI API key for RAGAS evaluation\n","# You'll need to ask the user to input this or securely store it\n","if \"OPENAI_API_KEY\" not in st.session_state:\n","    st.session_state.OPENAI_API_KEY = None\n","\n","# Mount Google Drive (needed for Colab)\n","try:\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","except:\n","    pass  # Not running in Colab\n","\n","# Set page configuration\n","st.set_page_config(\n","    page_title=\"LLM SQL Generator & Evaluator\",\n","    page_icon=\"üîç\",\n","    layout=\"wide\",\n","    initial_sidebar_state=\"expanded\"\n",")\n","\n","# Define model paths\n","MODEL_INFO = {\n","    \"Mistral-7B (Fine-tuned)\": {\n","        \"base\": \"unsloth/mistral-7b-instruct-v0.2\",\n","        \"adapter\": \"/content/drive/MyDrive/SQL-Generation/models/mistral_tuned\",\n","        \"type\": \"mistral\"\n","    },\n","    \"Llama-3-8B (Fine-tuned)\": {\n","        \"base\": \"unsloth/llama-3-8b-bnb-4bit\",\n","        \"adapter\": \"/content/drive/MyDrive/SQL-Generation/models/llama_tuned\",\n","        \"type\": \"llama\"\n","    },\n","    \"Phi-3-mini (Fine-tuned)\": {\n","        \"base\": \"unsloth/Phi-3-mini-4k-instruct\",\n","        \"adapter\": \"/content/drive/MyDrive/SQL-Generation/models/phi_tuned\",\n","        \"type\": \"phi\"\n","    }\n","}\n","\n","# Styles with added comparison table styling\n","st.markdown(\"\"\"\n","<style>\n","    .main-header {\n","        font-size: 2.5rem;\n","        font-weight: 600;\n","        color: #1E88E5;\n","    }\n","    .sub-header {\n","        font-size: 1.5rem;\n","        font-weight: 500;\n","        color: #42A5F5;\n","    }\n","    .success-box {\n","        background-color: #E8F5E9;\n","        padding: 20px;\n","        border-radius: 5px;\n","        border-left: 5px solid #4CAF50;\n","    }\n","    .info-box {\n","        background-color: #E3F2FD;\n","        padding: 20px;\n","        border-radius: 5px;\n","        border-left: 5px solid #2196F3;\n","    }\n","    .code-box {\n","        background-color: #263238;\n","        color: #FFFFFF;\n","        padding: 15px;\n","        border-radius: 5px;\n","        font-family: 'Courier New', Courier, monospace;\n","        overflow-x: auto;\n","    }\n","    .model-card {\n","        background-color: #F5F5F5;\n","        padding: 15px;\n","        border-radius: 5px;\n","        margin-bottom: 20px;\n","    }\n","    .mistral-box {\n","        border-left: 5px solid #4285F4;\n","    }\n","    .llama-box {\n","        border-left: 5px solid #FBBC04;\n","    }\n","    .phi-box {\n","        border-left: 5px solid #34A853;\n","    }\n","    .highlight {\n","        font-weight: 600;\n","        background-color: rgba(255, 235, 59, 0.2);\n","        padding: 0 5px;\n","    }\n","    .comparison-table {\n","        width: 100%;\n","        border-collapse: collapse;\n","    }\n","    .comparison-table th, .comparison-table td {\n","        padding: 8px 12px;\n","        text-align: left;\n","        border-bottom: 1px solid #ddd;\n","    }\n","    .comparison-table th {\n","        background-color: #f2f2f2;\n","    }\n","    .score-high {\n","        color: #4CAF50;\n","        font-weight: bold;\n","    }\n","    .score-medium {\n","        color: #FFC107;\n","        font-weight: bold;\n","    }\n","    .score-low {\n","        color: #F44336;\n","        font-weight: bold;\n","    }\n","</style>\n","\"\"\", unsafe_allow_html=True)\n","\n","@st.cache_resource\n","def load_model(model_key):\n","    \"\"\"Load model using model-specific approach\"\"\"\n","    model_info = MODEL_INFO[model_key]\n","\n","    try:\n","        with st.spinner(f\"Loading {model_key}...\"):\n","            # Load base model\n","            base_model, tokenizer = FastLanguageModel.from_pretrained(\n","                model_name=model_info[\"base\"],\n","                max_seq_length=2048,\n","                dtype=None,\n","                load_in_4bit=True\n","            )\n","\n","            # Special handling for Llama tokenizer\n","            if \"llama\" in model_info[\"base\"].lower():\n","                tokenizer.pad_token = tokenizer.eos_token\n","\n","            # Load adapter\n","            model = PeftModel.from_pretrained(base_model, model_info[\"adapter\"])\n","            FastLanguageModel.for_inference(model)\n","\n","            return model, tokenizer\n","    except Exception as e:\n","        st.error(f\"Error loading {model_key}: {e}\")\n","        return None, None\n","\n","def format_prompt(question, schema, model_type=\"mistral\"):\n","    \"\"\"Format input for the model based on model type\"\"\"\n","    if model_type == \"llama\":\n","        # Alpaca-style prompt format for Llama\n","        prompt = f\"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","        ### Instruction:\n","        Write a SQL query that answers the following question based on the given database schema. Use SQLite syntax.\n","\n","        ### Input:\n","        [SCHEMA] {schema}\n","        [QUESTION] {question}\n","\n","        ### Response:\n","        \"\"\"\n","    elif model_type == \"phi\":\n","        # Format optimized for Phi\n","        prompt = f\"\"\"You are a SQL expert. Follow these instructions and provide an appropriate response.\n","        # TASK:\n","        Create a SQL query that solves the given question using the provided database schema. Use standard SQLite syntax.\n","\n","        # CONTEXT:\n","        Database Schema:\n","        {schema}\n","\n","        Question:\n","        {question}\n","\n","        # RESPONSE:\n","        \"\"\"\n","    else:\n","        # Standard format for Mistral\n","        prompt = f\"\"\"You are a SQL expert. Follow these instructions and provide an appropriate response.\n","        # TASK:\n","        Create a SQL query that solves the given question using the provided database schema. Use standard SQLite syntax.\n","\n","        # CONTEXT:\n","        Database Schema:\n","        {schema}\n","\n","        Question:\n","        {question}\n","\n","        # RESPONSE:\n","        \"\"\"\n","    return prompt\n","\n","def clean_sql(sql, model_type=\"mistral\"):\n","    \"\"\"Clean generated SQL for display based on model type\"\"\"\n","    if model_type == \"llama\":\n","        # Clean Llama-specific formatting\n","        if \"### Response:\" in sql:\n","            sql = sql.split(\"### Response:\")[1]\n","\n","        sql = sql.replace(\"<|begin_of_text|>\", \"\")\n","        sql = sql.replace(\"<|end_of_text|>\", \"\")\n","    elif model_type == \"phi\":\n","        # Extract content after \"# RESPONSE:\" marker\n","        if \"# RESPONSE:\" in sql:\n","            # Get everything after \"# RESPONSE:\"\n","            response_part = sql.split(\"# RESPONSE:\")[1].strip()\n","\n","            # Find where the next section starts (if any)\n","            end_markers = [\"# EXPLANATION:\", \"# TASK:\", \"# CONTEXT:\", \"# QUESTION:\", '\"\"\"', \"Question:\"]\n","            end_pos = len(response_part)\n","\n","            for marker in end_markers:\n","                marker_pos = response_part.find(marker)\n","                if marker_pos != -1 and marker_pos < end_pos:\n","                    end_pos = marker_pos\n","\n","            # Extract just the SQL part\n","            sql = response_part[:end_pos].strip()\n","    else:\n","        # Standard cleaning for Mistral\n","        if \"# RESPONSE:\" in sql:\n","            sql = sql.split(\"# RESPONSE:\")[1]\n","\n","    # Common cleaning for all models\n","    sql = sql.replace(\"</s>\", \"\")\n","    sql = sql.replace(\"<|endoftext|>\", \"\")  # Fix for Phi model\n","    sql = sql.replace(\"[SQL QUERY]\", \"\")\n","    sql = sql.replace('\"\"\"', \"\")\n","    sql = sql.replace(\"```sql\", \"\")\n","    sql = sql.replace(\"```\", \"\")\n","\n","    # Trim whitespace\n","    sql = sql.strip()\n","\n","    return sql\n","\n","def generate_sql(model, tokenizer, question, schema, model_type=\"mistral\"):\n","    \"\"\"Generate SQL from question and schema\"\"\"\n","    prompt = format_prompt(question, schema, model_type)\n","\n","    # Tokenize and generate\n","    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    # Start timing\n","    start_time = time.time()\n","\n","    # Model-specific generation parameters\n","    if model_type == \"llama\":\n","        outputs = model.generate(\n","            **inputs,\n","            max_new_tokens=300,\n","            use_cache=True,\n","            temperature=0.7,\n","            do_sample=True,\n","            repetition_penalty=1.1\n","        )\n","    elif model_type == \"phi\":\n","        outputs = model.generate(\n","            **inputs,\n","            max_new_tokens=250,\n","            use_cache=True,\n","            temperature=0.2,\n","            do_sample=True\n","        )\n","    else:\n","        outputs = model.generate(\n","            **inputs,\n","            max_new_tokens=200,\n","            use_cache=True,\n","            temperature=0.1\n","        )\n","\n","    # End timing\n","    end_time = time.time()\n","\n","    # Decode the output\n","    result = tokenizer.batch_decode(outputs)[0]\n","\n","    # Clean the result\n","    cleaned_sql = clean_sql(result, model_type)\n","\n","    return cleaned_sql, end_time - start_time\n","\n","def highlight_sql_keywords(sql):\n","    \"\"\"Add syntax highlighting to SQL keywords\"\"\"\n","    keywords = [\n","        \"SELECT\", \"FROM\", \"WHERE\", \"JOIN\", \"GROUP BY\", \"ORDER BY\", \"HAVING\",\n","        \"INSERT\", \"UPDATE\", \"DELETE\", \"CREATE\", \"DROP\", \"ALTER\", \"TABLE\",\n","        \"AND\", \"OR\", \"NOT\", \"LIKE\", \"IN\", \"BETWEEN\", \"IS NULL\", \"IS NOT NULL\",\n","        \"ASC\", \"DESC\", \"DISTINCT\", \"COUNT\", \"SUM\", \"AVG\", \"MAX\", \"MIN\",\n","        \"INNER JOIN\", \"LEFT JOIN\", \"RIGHT JOIN\", \"FULL JOIN\", \"OUTER JOIN\",\n","        \"ON\", \"AS\", \"WITH\", \"UNION\", \"ALL\", \"CASE\", \"WHEN\", \"THEN\", \"ELSE\", \"END\"\n","    ]\n","\n","    # Sort keywords by length (longer first) to avoid partial matches\n","    keywords.sort(key=len, reverse=True)\n","\n","    # Create pattern to match keywords (case insensitive)\n","    pattern = r'\\b(' + '|'.join(keywords) + r')\\b'\n","\n","    # Replace keywords with highlighted version\n","    highlighted = re.sub(\n","        pattern,\n","        r'<span style=\"color: #FFA726; font-weight: bold;\">\\1</span>',\n","        sql,\n","        flags=re.IGNORECASE\n","    )\n","\n","    # Highlight string literals\n","    highlighted = re.sub(\n","        r\"'([^']*)'\",\n","        r'<span style=\"color: #66BB6A;\">\"\\1\"</span>',\n","        highlighted\n","    )\n","\n","    # Highlight numbers\n","    highlighted = re.sub(\n","        r'\\b(\\d+)\\b',\n","        r'<span style=\"color: #EF5350;\">\\1</span>',\n","        highlighted\n","    )\n","\n","    # Highlight function calls\n","    highlighted = re.sub(\n","        r'\\b(\\w+)\\(',\n","        r'<span style=\"color: #42A5F5;\">\\1</span>(',\n","        highlighted\n","    )\n","\n","    return highlighted\n","\n","def check_syntax_validity(sql):\n","    \"\"\"Check if the SQL syntax is valid using sqlglot\"\"\"\n","    try:\n","        if sql and len(sql) > 5:\n","            sqlglot.parse(sql)\n","            return True\n","        return False\n","    except Exception:\n","        return False\n","\n","async def custom_evaluate_queries(sql_queries, reference_query, schema):\n","    \"\"\"Custom evaluation using direct GPT-4 calls - binary scoring approach\"\"\"\n","    if not st.session_state.OPENAI_API_KEY:\n","        st.warning(\"OpenAI API key not set. Skipping semantic evaluation.\")\n","        return None\n","\n","    client = openai.OpenAI(api_key=st.session_state.OPENAI_API_KEY)\n","    results = {}\n","\n","    # st.info(f\"Starting custom semantic evaluation with {len(sql_queries)} queries\")\n","\n","    for model_name, sql in sql_queries.items():\n","        try:\n","            # st.info(f\"Evaluating {model_name} query...\")\n","\n","            prompt = f\"\"\"\n","            You are a SQL expert. Determine if this query correctly answers the question based on the given schema.\n","\n","            Database Schema:\n","            {schema}\n","\n","            Reference Query (known to be correct):\n","            {reference_query}\n","\n","            Query to Evaluate:\n","            {sql}\n","\n","            If the query is correct (would provide the same results as the reference query), respond with \"1.0\".\n","            If the query is incorrect, respond with a number between 0.0 and 0.9 that represents how close it is to being correct.\n","\n","            Respond ONLY with a single number.\n","            \"\"\"\n","\n","            response = client.chat.completions.create(\n","                model=\"gpt-4o\",\n","                messages=[\n","                    {\"role\": \"system\", \"content\": \"You are an expert SQL evaluator.\"},\n","                    {\"role\": \"user\", \"content\": prompt}\n","                ],\n","                temperature=0\n","            )\n","\n","            score_text = response.choices[0].message.content.strip()\n","\n","            # Extract numeric score\n","            try:\n","                score = float(score_text)\n","                if score < 0 or score > 1:\n","                    score = max(0, min(float(score), 1))  # Ensure it's between 0 and 1\n","            except ValueError:\n","                # If not a clean number, try to find any number in the response\n","                import re\n","                match = re.search(r\"([0-9]*\\.?[0-9]+)\", score_text)\n","                if match:\n","                    score = float(match.group(1))\n","                else:\n","                    st.warning(f\"Couldn't extract score from: {score_text}\")\n","                    score = 0.5  # Default mid-range score\n","\n","            results[model_name] = score\n","            # st.success(f\"Successfully evaluated {model_name}: Score = {score}\")\n","\n","        except Exception as e:\n","            st.error(f\"Error evaluating {model_name}: {str(e)}\")\n","            results[model_name] = 0.0\n","\n","    return results\n","\n","async def evaluate_semantic_equivalence(sql_queries, reference_query, schema):\n","    \"\"\"Evaluate semantic equivalence using RAGAS - fixed version\"\"\"\n","    if not st.session_state.OPENAI_API_KEY:\n","        st.warning(\"OpenAI API key not set. Skipping semantic evaluation.\")\n","        return None\n","\n","    # Set OpenAI API key\n","    os.environ[\"OPENAI_API_KEY\"] = st.session_state.OPENAI_API_KEY\n","    client = openai.OpenAI(api_key=st.session_state.OPENAI_API_KEY)\n","\n","    # Initialize RAGAS evaluator\n","    semantic_checker = LLMSQLEquivalence()\n","    semantic_checker.llm = llm_factory(model=\"gpt-4o\")\n","\n","    # Log for debugging\n","    st.info(f\"Starting semantic evaluation with {len(sql_queries)} queries\")\n","\n","    results = {}\n","\n","    for model_name, sql in sql_queries.items():\n","        try:\n","            # st.info(f\"Evaluating {model_name} query: {sql[:100]}...\")\n","            # This matches the reference implementation's approach\n","            sample = SingleTurnSample(\n","                response=sql,\n","                reference=reference_query,\n","                reference_contexts=[schema]  # Changed to match your sample code\n","            )\n","\n","            # Try with direct OpenAI call if RAGAS is failing\n","            try:\n","                score = await semantic_checker.single_turn_ascore(sample)\n","                st.success(f\"RAGAS evaluation succeeded for {model_name}\")\n","            except Exception as e:\n","                st.error(f\"RAGAS evaluation failed: {e}. Trying direct OpenAI call...\")\n","\n","                prompt = f\"\"\"\n","                Are these two SQL queries semantically equivalent? They should return the same results.\n","\n","                Query 1: {reference_query}\n","\n","                Query 2: {sql}\n","\n","                Schema information: {schema}\n","\n","                Score from 0.0 to 1.0, where 1.0 means completely equivalent:\n","                \"\"\"\n","\n","                response = client.chat.completions.create(\n","                    model=\"gpt-4o\",\n","                    messages=[\n","                        {\"role\": \"system\", \"content\": \"You are a SQL expert evaluating query equivalence.\"},\n","                        {\"role\": \"user\", \"content\": prompt}\n","                    ],\n","                    temperature=0\n","                )\n","\n","                # Try to extract a score from the response\n","                score_text = response.choices[0].message.content.strip()\n","\n","                try:\n","                    score = float(score_text)\n","                except:\n","                    # If we can't extract a clean number, look for a number in the text\n","                    import re\n","                    match = re.search(r\"([0-9]*\\.?[0-9]+)\", score_text)\n","                    if match:\n","                        score = float(match.group(1))\n","                    else:\n","                        score = 0.0\n","\n","            results[model_name] = float(score)\n","            # st.info(f\"Successfully evaluated {model_name}: Score = {score}\")\n","\n","        except Exception as e:\n","            st.error(f\"All evaluation methods failed for {model_name}: {str(e)}\")\n","            results[model_name] = 0.0\n","\n","    return results\n","\n","def get_reference_query(question, schema):\n","    \"\"\"Get a reference SQL query from GPT-4 to use as ground truth\"\"\"\n","    if not st.session_state.OPENAI_API_KEY:\n","        return None\n","\n","    client = openai.OpenAI(api_key=st.session_state.OPENAI_API_KEY)\n","\n","    prompt = f\"\"\"Generate a correct SQL query for the following question and schema, without any explanations:\n","\n","    Schema:\n","    {schema}\n","\n","    Question:\n","    {question}\n","\n","    SQL Query:\"\"\"\n","\n","    try:\n","        response = client.chat.completions.create(\n","            model=\"gpt-4o\",\n","            messages=[{\"role\": \"system\", \"content\": \"You are an expert SQL developer.\"},\n","                      {\"role\": \"user\", \"content\": prompt}],\n","            temperature=0\n","        )\n","\n","        # Extract just the SQL from the response\n","        sql = response.choices[0].message.content.strip()\n","\n","        # Remove any explanation text around the SQL\n","        sql_keywords = [\"SELECT\", \"INSERT\", \"UPDATE\", \"DELETE\", \"CREATE\", \"DROP\", \"ALTER\", \"WITH\"]\n","        start_idx = 0\n","        for keyword in sql_keywords:\n","            if keyword in sql.upper():\n","                keyword_idx = sql.upper().find(keyword)\n","                if keyword_idx > -1:\n","                    start_idx = keyword_idx\n","                    break\n","\n","        # Extract just the SQL part\n","        sql = sql[start_idx:].strip()\n","        return sql\n","    except Exception as e:\n","        st.error(f\"Error getting reference query: {str(e)}\")\n","        return None\n","\n","# Initialize session state for models\n","if 'models' not in st.session_state:\n","    st.session_state.models = {}\n","    st.session_state.tokenizers = {}\n","    st.session_state.loaded_models = []\n","\n","# App header\n","st.markdown('<p class=\"main-header\">LLM SQL Generator & Evaluator</p>', unsafe_allow_html=True)\n","st.markdown(\"\"\"\n","This application uses fine-tuned language models to generate SQL queries from natural language descriptions.\n","Provide a database schema and a question, and see how different models respond! The app also evaluates query quality.\n","\"\"\")\n","\n","# Sidebar for API key and model loading\n","st.sidebar.markdown('<p class=\"sub-header\">Settings</p>', unsafe_allow_html=True)\n","\n","# OpenAI API key input\n","openai_api_key = st.sidebar.text_input(\n","    \"OpenAI API Key (for RAGAS evaluation)\",\n","    type=\"password\",\n","    value=st.session_state.OPENAI_API_KEY if st.session_state.OPENAI_API_KEY else \"\",\n","    help=\"Required for semantic evaluation of SQL queries\"\n",")\n","\n","if openai_api_key:\n","    st.session_state.OPENAI_API_KEY = openai_api_key\n","    st.sidebar.success(\"API key set!\")\n","\n","# Model loading section\n","st.sidebar.markdown('<p class=\"sub-header\">Model Loading</p>', unsafe_allow_html=True)\n","\n","# Load all models at startup\n","if not st.session_state.loaded_models:\n","    progress_bar = st.sidebar.progress(0)\n","    st.sidebar.info(\"Loading models... this may take a few minutes\")\n","\n","    i = 0\n","    total_models = len(MODEL_INFO)\n","\n","    for model_name, model_info in MODEL_INFO.items():\n","        i += 1\n","        progress_bar.progress(i/total_models)\n","\n","        # Try to load the model\n","        model, tokenizer = load_model(model_name)\n","\n","        if model is not None:\n","            st.session_state.models[model_name] = model\n","            st.session_state.tokenizers[model_name] = tokenizer\n","            st.session_state.loaded_models.append(model_name)\n","            st.sidebar.success(f\"{model_name} loaded successfully!\")\n","        else:\n","            st.sidebar.error(f\"Failed to load {model_name}\")\n","\n","    progress_bar.empty()\n","\n","# Show loaded models\n","st.sidebar.subheader(\"Loaded Models:\")\n","for model_name in st.session_state.loaded_models:\n","    st.sidebar.success(f\"‚úÖ {model_name}\")\n","\n","# Main content\n","st.markdown('<p class=\"sub-header\">SQL Query Generator</p>', unsafe_allow_html=True)\n","\n","# Show sample database schemas\n","with st.expander(\"Sample Database Schemas (Click to expand)\", expanded=False):\n","    st.markdown(\"\"\"\n","    ### E-commerce Database\n","    ```sql\n","    CREATE TABLE customers (customer_id INT, name TEXT, email TEXT, registration_date DATE);\n","    CREATE TABLE products (product_id INT, name TEXT, category TEXT, price REAL, stock INT);\n","    CREATE TABLE orders (order_id INT, customer_id INT, order_date DATE, total_amount REAL);\n","    CREATE TABLE order_items (order_id INT, product_id INT, quantity INT, price REAL);\n","    ```\n","\n","    ### Employee Management\n","    ```sql\n","    CREATE TABLE departments (dept_id INT, name TEXT, location TEXT);\n","    CREATE TABLE employees (emp_id INT, name TEXT, dept_id INT, salary REAL, hire_date DATE);\n","    CREATE TABLE projects (project_id INT, name TEXT, start_date DATE, end_date DATE);\n","    CREATE TABLE project_assignments (emp_id INT, project_id INT, role TEXT);\n","    ```\n","    \"\"\")\n","\n","# Input form\n","with st.form(\"query_form\"):\n","    col1, col2 = st.columns(2)\n","\n","    with col1:\n","        schema = st.text_area(\n","            \"Database Schema (SQL CREATE statements)\",\n","            height=200,\n","            placeholder=\"CREATE TABLE users (id INT, name TEXT, email TEXT);\\nCREATE TABLE orders (id INT, user_id INT, amount REAL, date DATE);\"\n","        )\n","\n","    with col2:\n","        question = st.text_area(\n","            \"Your Question\",\n","            height=200,\n","            placeholder=\"What is the total amount spent by each user, ordered by highest amount first?\"\n","        )\n","\n","    with_evaluation = st.checkbox(\"Include RAGAS evaluation (requires OpenAI API key)\", value=st.session_state.OPENAI_API_KEY is not None)\n","\n","    submitted = st.form_submit_button(\"Generate SQL Query from All Models\")\n","\n","# Generate and display SQL queries from all loaded models\n","if submitted and schema and question:\n","    if not st.session_state.loaded_models:\n","        st.error(\"No models have been successfully loaded. Please check the console for errors.\")\n","    else:\n","        st.success(f\"Generating SQL queries using {len(st.session_state.loaded_models)} models...\")\n","\n","        tabs = st.tabs([\"All Models\"] + st.session_state.loaded_models)\n","\n","        all_results = {}\n","\n","        # Generate SQL with each model\n","        for model_name in st.session_state.loaded_models:\n","            model = st.session_state.models[model_name]\n","            tokenizer = st.session_state.tokenizers[model_name]\n","            model_type = MODEL_INFO[model_name][\"type\"]\n","\n","            try:\n","                sql_query, generation_time = generate_sql(\n","                    model,\n","                    tokenizer,\n","                    question,\n","                    schema,\n","                    model_type\n","                )\n","\n","                # Check syntax validity\n","                syntax_valid = check_syntax_validity(sql_query)\n","\n","                all_results[model_name] = {\n","                    \"sql\": sql_query,\n","                    \"time\": generation_time,\n","                    \"syntax_valid\": syntax_valid\n","                }\n","            except Exception as e:\n","                all_results[model_name] = {\n","                    \"error\": str(e)\n","                }\n","\n","        # Generate reference query from GPT-4 if evaluation is enabled\n","        reference_query = None\n","        semantic_scores = None\n","\n","        if with_evaluation and st.session_state.OPENAI_API_KEY:\n","            with st.spinner(\"Generating reference SQL query using GPT-4...\"):\n","                reference_query = get_reference_query(question, schema)\n","\n","                if reference_query:\n","                    st.info(\"Reference query generated for evaluation\")\n","\n","                    # Only include SQL queries, not errors\n","                    valid_queries = {model: result[\"sql\"] for model, result in all_results.items()\n","                                    if \"sql\" in result}\n","\n","                    # Evaluate semantic equivalence\n","                    with st.spinner(\"Evaluating semantic equivalence...\"):\n","                        # semantic_scores = asyncio.run(\n","                        #     evaluate_semantic_equivalence(valid_queries, reference_query, schema)\n","                        # )\n","                        semantic_scores = asyncio.run(custom_evaluate_queries(valid_queries, reference_query, schema))\n","\n","                        # Add scores to results\n","                        for model_name, score in semantic_scores.items():\n","                            all_results[model_name][\"semantic_score\"] = score\n","\n","        # All Models Tab\n","        with tabs[0]:\n","            # First show reference query if available\n","            if reference_query:\n","                st.markdown('<div class=\"info-box\">', unsafe_allow_html=True)\n","                st.markdown(\"### Reference Query (GPT-4)\")\n","                st.code(reference_query, language=\"sql\")\n","                st.markdown('</div>', unsafe_allow_html=True)\n","\n","            # Display comparison table if we have semantic scores\n","            if semantic_scores:\n","                st.markdown(\"### Model Performance Comparison\")\n","\n","                # Create DataFrame for comparison\n","                comparison_data = []\n","                for model_name in st.session_state.loaded_models:\n","                    if model_name in all_results and \"error\" not in all_results[model_name]:\n","                        result = all_results[model_name]\n","                        comparison_data.append({\n","                            \"Model\": model_name,\n","                            \"Generation Time (s)\": f\"{result['time']:.2f}\",\n","                            \"Syntax Valid\": \"‚úÖ\" if result.get(\"syntax_valid\", False) else \"‚ùå\",\n","                            \"Semantic Score\": f\"{result.get('semantic_score', 0):.2f}\"\n","                        })\n","\n","                comparison_df = pd.DataFrame(comparison_data)\n","                st.table(comparison_df)\n","\n","            # Display individual model results\n","            for i, model_name in enumerate(st.session_state.loaded_models, 1):\n","                model_result = all_results[model_name]\n","                model_type = MODEL_INFO[model_name][\"type\"]\n","                model_box_class = f\"{model_type}-box model-card\"\n","\n","                st.markdown(f'<div class=\"{model_box_class}\">', unsafe_allow_html=True)\n","                st.subheader(f\"{model_name}\")\n","\n","                if \"error\" in model_result:\n","                    st.error(f\"Error: {model_result['error']}\")\n","                else:\n","                    metrics_col1, metrics_col2 = st.columns(2)\n","\n","                    with metrics_col1:\n","                        st.metric(\"Generation Time\", f\"{model_result['time']:.2f}s\")\n","\n","                    with metrics_col2:\n","                        if model_result.get(\"syntax_valid\", False):\n","                            st.success(\"‚úÖ Syntax Valid\")\n","                        else:\n","                            st.error(\"‚ùå Invalid Syntax\")\n","\n","                    if \"semantic_score\" in model_result:\n","                        score = model_result[\"semantic_score\"]\n","                        score_class = \"score-high\" if score > 0.7 else \"score-medium\" if score > 0.4 else \"score-low\"\n","                        st.markdown(f'<p>Semantic Equivalence: <span class=\"{score_class}\">{score:.2f}</span></p>', unsafe_allow_html=True)\n","\n","                    # Only show the copy button version\n","                    st.code(model_result['sql'], language=\"sql\")\n","\n","                st.markdown('</div>', unsafe_allow_html=True)\n","\n","        # Individual Model Tabs\n","        for i, model_name in enumerate(st.session_state.loaded_models, 1):\n","            with tabs[i]:\n","                model_result = all_results[model_name]\n","\n","                if \"error\" in model_result:\n","                    st.error(f\"Error: {model_result['error']}\")\n","                else:\n","                    st.success(f\"SQL query generated in {model_result['time']:.2f} seconds\")\n","\n","                    # Display syntax validation result\n","                    if model_result.get(\"syntax_valid\", False):\n","                        st.success(\"‚úÖ SQL syntax is valid\")\n","                    else:\n","                        st.error(\"‚ùå SQL syntax is invalid\")\n","\n","                    # Display semantic score if available\n","                    if \"semantic_score\" in model_result:\n","                        score = model_result[\"semantic_score\"]\n","                        if score > 0.7:\n","                            st.success(f\"‚úÖ Semantic equivalence score: {score:.2f}/1.0 (Good)\")\n","                        elif score > 0.4:\n","                            st.warning(f\"‚ö†Ô∏è Semantic equivalence score: {score:.2f}/1.0 (Fair)\")\n","                        else:\n","                            st.error(f\"‚ùå Semantic equivalence score: {score:.2f}/1.0 (Poor)\")\n","\n","                    # Only show the code block\n","                    st.code(model_result['sql'], language=\"sql\")\n","\n","                    # If we have a reference, show comparison\n","                    if reference_query:\n","                        st.markdown(\"### Reference Query (GPT-4)\")\n","                        st.code(reference_query, language=\"sql\")\n","\n","                    with st.expander(\"Model Details\", expanded=False):\n","                        st.markdown(f\"\"\"\n","                        - **Model**: {model_name}\n","                        - **Generation Time**: {model_result['time']:.2f} seconds\n","                        - **Output Token Count**: ~{len(model_result['sql'].split())} tokens\n","                        \"\"\")\n","\n","elif submitted:\n","    st.warning(\"Please provide both a database schema and a question.\")\n","\n","# Sample questions\n","st.markdown('<p class=\"sub-header\">Sample Questions</p>', unsafe_allow_html=True)\n","st.markdown('<div class=\"info-box\">', unsafe_allow_html=True)\n","st.markdown(\"\"\"\n","Try these sample questions with the appropriate schema:\n","\n","1. **For E-commerce:**\n","   - What are the top 5 most purchased products?\n","   - Find customers who spent more than $1000 in total.\n","   - How many orders were placed in each month of 2023?\n","\n","2. **For Employee Management:**\n","   - What is the average salary by department?\n","   - Which employees are assigned to multiple projects?\n","   - List all employees hired in the last year with their department names.\n","\"\"\")\n","st.markdown('</div>', unsafe_allow_html=True)\n","\n","# Footer\n","st.markdown(\"---\")\n","st.markdown(\"LLM SQL Generator | Built with Streamlit, Unsloth, and PyTorch\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cn1vIO6piXKq","executionInfo":{"status":"ok","timestamp":1745545207845,"user_tz":240,"elapsed":84,"user":{"displayName":"gscolabpro","userId":"15075203482406901392"}},"outputId":"bd607830-9c47-415f-f1d2-871dac43185b"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing sql_generator_app.py\n"]}]},{"cell_type":"markdown","source":["# THIS IS THE FINAL NGROK CELL TO HOST THE UI (RUN THIS CELL THEN CLICK .NGROK-FREE.APP)"],"metadata":{"id":"hceSZdK8mt5g"}},{"cell_type":"code","source":["# Import necessary libraries\n","from pyngrok import ngrok\n","import os\n","\n","# Set ngrok auth token\n","ngrok.set_auth_token(\"2u32iphqQT5Wyb5Ms0dW4KJO0Uu_4sUC1x7wNNCkRG3phcFP\")\n","\n","# Kill any existing ngrok tunnels\n","ngrok.kill()\n","\n","# Specify the path to your Streamlit app\n","app_path = \"sql_generator_app.py\"\n","\n","# Check if Streamlit file exists\n","if not os.path.exists(app_path):\n","    print(f\"Error: {app_path} does not exist\")\n","    exit(1)\n","\n","# Start Streamlit directly using os.system\n","os.system(f\"streamlit run {app_path} &\")\n","\n","# Wait longer for Streamlit to start up\n","import time\n","print(\"Waiting for Streamlit to start (60 seconds)...\")\n","time.sleep(60)  # Wait a full minute for Streamlit to initialize\n","\n","# Create the ngrok tunnel\n","print(\"Creating ngrok tunnel...\")\n","try:\n","    public_url = ngrok.connect(8501)\n","    print(f\"Public URL: {public_url}\")\n","except Exception as e:\n","    print(f\"Error connecting ngrok: {e}\")\n","    # Try again with explicit hostname\n","    try:\n","        public_url = ngrok.connect(addr=\"localhost:8501\", bind_tls=True)\n","        print(f\"Public URL: {public_url}\")\n","    except Exception as e:\n","        print(f\"Error on second attempt: {e}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yhytipt2G3e_","outputId":"7231d610-104c-426e-d37e-3802363e1978","executionInfo":{"status":"ok","timestamp":1745545323586,"user_tz":240,"elapsed":61571,"user":{"displayName":"gscolabpro","userId":"15075203482406901392"}}},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Waiting for Streamlit to start (60 seconds)...\n","Creating ngrok tunnel...\n","Public URL: NgrokTunnel: \"https://0e14-34-71-30-75.ngrok-free.app\" -> \"http://localhost:8501\"\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"2dKQIPs0IFxO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"hVNkYjWuPOB1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"JUFrVxX0MUr1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"bWRjnRcU6VFx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"lNk5TwQ1oqaJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"VpD0U80-oqYS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"lakTEfiroqWB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"UHd67NhkoqTy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"mMEivWiooqRf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"8tO7bIwOoqPI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Sde7pwk1oqMx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"gvJj45RmoqKd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"9jCPkAjvoqG4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"kMNFD68LoqDA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"r3VmOOM7op_x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"rBTbgEy4op8c"},"execution_count":null,"outputs":[]}]}